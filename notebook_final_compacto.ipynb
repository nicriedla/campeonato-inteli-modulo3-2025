{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a377fa",
   "metadata": {},
   "source": [
    "# Notebook Final Compacto\n",
    "Este arquivo contém somente as etapas essenciais para: (1) Treinar o ensemble final (RandomForest + ExtraTrees + HistGradientBoosting + LogisticRegression opcional como meta/blender simples), (2) Gerar métricas de validação cruzada (accuracy principal) e (3) Produzir o arquivo de submissão.\n",
    "\n",
    "Regras atendidas: Uso exclusivo de Numpy / Pandas / Scikit-Learn (+ matplotlib opcional).\n",
    "\n",
    "Para detalhes de EDA, hipóteses e justificativas, ver notebook completo original (`teste.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14adba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports essenciais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIR = Path('.')\n",
    "TRAIN_PATH = DATA_DIR / 'train.csv'\n",
    "TEST_PATH = DATA_DIR / 'test.csv'\n",
    "SUB_PATH = DATA_DIR / 'sample_submission.csv'\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf2e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train: (646, 32) Shape test: (277, 32)\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "submission = pd.read_csv(SUB_PATH)\n",
    "target_col = 'target' if 'target' in train.columns else train.columns[-1]  # ajuste se necessário\n",
    "y = train[target_col].values\n",
    "X = train.drop(columns=[target_col]).copy()\n",
    "X_test = test.copy()\n",
    "print('Shape train:', X.shape, 'Shape test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b417332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cols categóricas: 24 | numéricas: 8\n"
     ]
    }
   ],
   "source": [
    "# Detecção simples de tipos e separação cat/num\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == 'object' or X[c].nunique() < 20]  # heurística rápida\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "print(f'Cols categóricas: {len(cat_cols)} | numéricas: {len(num_cols)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b0efe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função utilitária: target encoding OOF para alta cardinalidade (opcional, aplica só se necessário)\n",
    "def target_encode_oof(series, y, n_splits=5, smoothing=5, noise_std=0.0, random_state=42):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    global_mean = y.mean()\n",
    "    oof = pd.Series(index=series.index, dtype=float)\n",
    "    for tr_idx, val_idx in skf.split(series, y):\n",
    "        tr_values = series.iloc[tr_idx]\n",
    "        tr_target = y[tr_idx]\n",
    "        stats = tr_values.to_frame('cat').join(pd.Series(tr_target, index=tr_values.index, name='y'))\\\n",
    "            .groupby('cat')['y'].agg(['mean','count'])\n",
    "        counts = stats['count']\n",
    "        means = stats['mean']\n",
    "        smooth = (counts * means + smoothing * global_mean) / (counts + smoothing)\n",
    "        mapping = smooth.to_dict()\n",
    "        oof.iloc[val_idx] = series.iloc[val_idx].map(mapping).fillna(global_mean)\n",
    "    if noise_std > 0:\n",
    "        oof += np.random.normal(0, noise_std, size=len(oof))\n",
    "    return oof.values, global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e31b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categórico concluído.\n"
     ]
    }
   ],
   "source": [
    "# Aplicar encoding simples: para colunas categóricas pequenas usar OrdinalEncoder;\n",
    "# (Se houver col. de alta cardinalidade, poderia aplicar target encoding, mas aqui mantemos simples)\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X_enc = X.copy()\n",
    "X_test_enc = X_test.copy()\n",
    "if cat_cols:\n",
    "    X_enc[cat_cols] = encoder.fit_transform(X_enc[cat_cols])\n",
    "    X_test_enc[cat_cols] = encoder.transform(X_test_enc[cat_cols])\n",
    "print('Encoding categórico concluído.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd5b6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cols baixa variância removidas: []\n"
     ]
    }
   ],
   "source": [
    "# (Opcional) Remover colunas quase constantes rapidamente\n",
    "low_var_cols = [c for c in X_enc.columns if X_enc[c].nunique() <= 1]\n",
    "if low_var_cols:\n",
    "    X_enc.drop(columns=low_var_cols, inplace=True)\n",
    "    X_test_enc.drop(columns=[c for c in low_var_cols if c in X_test_enc.columns], inplace=True)\n",
    "print('Cols baixa variância removidas:', low_var_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0413b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selecionadas: 28\n"
     ]
    }
   ],
   "source": [
    "# Seleção simples baseada em ExtraTrees para manter top k features (k proporcional)\n",
    "def select_features_via_importance(X_mat, y, keep_pct=0.9, random_state=42):\n",
    "    et = ExtraTreesClassifier(n_estimators=400, random_state=random_state, n_jobs=-1)\n",
    "    et.fit(X_mat, y)\n",
    "    importances = pd.Series(et.feature_importances_, index=X_mat.columns).sort_values(ascending=False)\n",
    "    k = max(5, int(len(importances) * keep_pct))\n",
    "    selected = importances.index[:k].tolist()\n",
    "    return selected, importances\n",
    "\n",
    "selected_features, importances = select_features_via_importance(X_enc, y, keep_pct=0.9, random_state=RANDOM_STATE)\n",
    "print('Features selecionadas:', len(selected_features))\n",
    "X_sel = X_enc[selected_features]\n",
    "X_test_sel = X_test_enc[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e546961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos base\n",
    "rf = RandomForestClassifier(n_estimators=800, max_depth=None, min_samples_split=2, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "et = ExtraTreesClassifier(n_estimators=1000, max_depth=None, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "hgb = HistGradientBoostingClassifier(max_depth=None, learning_rate=0.06, max_leaf_nodes=31, random_state=RANDOM_STATE)\n",
    "log_meta = LogisticRegression(max_iter=1000, n_jobs=None) if 'LogisticRegression' else None  # placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14df91e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor peso global encontrado: (0.33, 0.33, 0.34)\n",
      "Acurácias por fold: [0.8172 0.7742 0.7935 0.7826 0.7391 0.8152 0.8261]\n",
      "CV Accuracy: 0.7926 | Precision: 0.7934 | Recall: 0.9187 | F1: 0.8514\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation com blending simples (pesos otimizados por busca discreta curta)\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "oof_preds = np.zeros(len(X_sel))\n",
    "test_preds_collect = []\n",
    "weights_grid = [(0.33,0.33,0.34),(0.4,0.3,0.3),(0.5,0.25,0.25),(0.34,0.4,0.26),(0.37,0.33,0.30)]\n",
    "best_w = None; best_acc = -1\n",
    "fold_metrics = []\n",
    "for fold,(tr_idx,val_idx) in enumerate(skf.split(X_sel, y),1):\n",
    "    X_tr, X_val = X_sel.iloc[tr_idx], X_sel.iloc[val_idx]\n",
    "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "    rf.fit(X_tr, y_tr)\n",
    "    et.fit(X_tr, y_tr)\n",
    "    hgb.fit(X_tr, y_tr)\n",
    "    prf = rf.predict_proba(X_val)[:,1]\n",
    "    pet = et.predict_proba(X_val)[:,1]\n",
    "    phg = hgb.predict_proba(X_val)[:,1]\n",
    "    # Escolher melhor peso por acurácia local\n",
    "    local_best = -1; local_w = None; local_pred = None\n",
    "    for wr,we,wh in weights_grid:\n",
    "        blend = wr*prf + we*pet + wh*phg\n",
    "        pred_label = (blend >= 0.5).astype(int)\n",
    "        acc = accuracy_score(y_val, pred_label)\n",
    "        if acc > local_best:\n",
    "            local_best = acc; local_w = (wr,we,wh); local_pred = blend\n",
    "    oof_preds[val_idx] = local_pred\n",
    "    if local_best > best_acc:\n",
    "        best_acc = local_best; best_w = local_w\n",
    "    fold_metrics.append(local_best)\n",
    "    # Predições em test para este fold\n",
    "    prf_t = rf.predict_proba(X_test_sel)[:,1]\n",
    "    pet_t = et.predict_proba(X_test_sel)[:,1]\n",
    "    phg_t = hgb.predict_proba(X_test_sel)[:,1]\n",
    "    test_preds_collect.append(local_w[0]*prf_t + local_w[1]*pet_t + local_w[2]*phg_t)\n",
    "print('Melhor peso global encontrado:', best_w)\n",
    "print('Acurácias por fold:', np.round(fold_metrics,4))\n",
    "oof_labels = (oof_preds >= 0.5).astype(int)\n",
    "cv_accuracy = accuracy_score(y, oof_labels)\n",
    "cv_precision = precision_score(y, oof_labels)\n",
    "cv_recall = recall_score(y, oof_labels)\n",
    "cv_f1 = f1_score(y, oof_labels)\n",
    "print(f'CV Accuracy: {cv_accuracy:.4f} | Precision: {cv_precision:.4f} | Recall: {cv_recall:.4f} | F1: {cv_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "617ae0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor threshold: 0.500 | Accuracy OOF: 0.7926\n"
     ]
    }
   ],
   "source": [
    "# Threshold tuning rápido (grid simples) para maximizar accuracy OOF\n",
    "best_thr = 0.5; best_thr_acc = -1\n",
    "for thr in np.linspace(0.3,0.7,21):\n",
    "    pred_l = (oof_preds >= thr).astype(int)\n",
    "    acc = accuracy_score(y, pred_l)\n",
    "    if acc > best_thr_acc:\n",
    "        best_thr_acc = acc; best_thr = thr\n",
    "print(f'Melhor threshold: {best_thr:.3f} | Accuracy OOF: {best_thr_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98c7d812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo de submissão salvo em: submission_compacto_thr0.500.csv\n"
     ]
    }
   ],
   "source": [
    "# Predição final (média das predições por fold já ponderadas)\n",
    "final_proba = np.mean(test_preds_collect, axis=0)\n",
    "final_label = (final_proba >= best_thr).astype(int)\n",
    "submission[target_col] = final_label\n",
    "out_name = f'submission_compacto_thr{best_thr:.3f}.csv'\n",
    "submission.to_csv(out_name, index=False)\n",
    "print('Arquivo de submissão salvo em:', out_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d1867",
   "metadata": {},
   "source": [
    "## Notas finais\n",
    "- Este notebook compacto não inclui EDA detalhada.\n",
    "- Pesos do ensemble selecionados por busca discreta local em cada fold; melhor combinação global registrada.\n",
    "- Ajuste simples de threshold para maximizar accuracy.\n",
    "- Para explicações completas (hipóteses, gráficos, seleção de features), consultar notebook expandido original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
