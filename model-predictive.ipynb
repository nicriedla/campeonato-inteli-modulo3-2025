{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71df7593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ADV) Cat=24 | High-card=1 | Num=8\n",
      "Interações adicionadas: ['id_div_age_first_funding_year', 'id_minus_age_first_funding_year', 'age_first_funding_year_div_age_last_funding_year', 'age_first_funding_year_minus_age_last_funding_year', 'age_last_funding_year_div_age_first_milestone_year', 'age_last_funding_year_minus_age_first_milestone_year']\n",
      "Low variance removidas: []\n",
      "Seleção multi keep -> 0.95 acc=0.7801\n",
      "Fold mean acc (equal weights): 0.7786\n",
      "Pesos finais: {'rf_deep': np.float64(0.0856), 'rf_shallow': np.float64(0.3404), 'et': np.float64(0.1623), 'gb': np.float64(0.4118), 'hgb': np.float64(0.0)} score= 0.7849\n",
      "Blend acc thr=0.5: 0.791\n",
      "Stack LR thr=0.5 acc: 0.7864 | Stack RF thr=0.5 acc: 0.8406\n",
      "Blend opt thr=0.5000 acc=0.7910\n",
      "Stack LR opt thr=0.5600 acc=0.7926\n",
      "Stack RF opt thr=0.4380 acc=0.8483\n",
      "Melhor opção: stack_rf acc= 0.8483 thr= 0.438\n",
      "{'final_acc': 0.848297213622291, 'precision': 0.82, 'recall': 0.9808612440191388, 'f1': 0.8932461873638344, 'threshold': np.float64(0.43799999999999994), 'mode': 'stack_rf', 'weights': {'rf_deep': np.float64(0.0856), 'rf_shallow': np.float64(0.3404), 'et': np.float64(0.1623), 'gb': np.float64(0.4118), 'hgb': np.float64(0.0)}, 'features_used': 37, 'submission_file': 'submission_advanced_stack_rf_thr0.4380.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Advanced Stacking Implementation\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier,\n",
    "                              HistGradientBoostingClassifier, GradientBoostingClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "# Config\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 7\n",
    "DATA_DIR = Path('.')\n",
    "TRAIN_PATH = DATA_DIR / 'train.csv'\n",
    "TEST_PATH = DATA_DIR / 'test.csv'\n",
    "SUB_PATH = DATA_DIR / 'sample_submission.csv'\n",
    "ENABLE_INTERACTIONS = True\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "X_test = pd.read_csv(TEST_PATH)\n",
    "submission_adv = pd.read_csv(SUB_PATH)\n",
    "\n",
    "# Detect target\n",
    "target_col = 'target' if 'target' in train.columns else train.columns[-1]\n",
    "y = train[target_col].values\n",
    "X = train.drop(columns=[target_col]).copy()\n",
    "\n",
    "# 1. Type detection\n",
    "cat_cols, num_cols, high_card_cols = [], [], []\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == 'object' or X[c].dtype.name.startswith('category'):\n",
    "        nun = X[c].nunique()\n",
    "        if nun > 25: high_card_cols.append(c)\n",
    "        cat_cols.append(c)\n",
    "    else:\n",
    "        nun = X[c].nunique()\n",
    "        if 2 <= nun < 15: cat_cols.append(c)\n",
    "        else: num_cols.append(c)\n",
    "print(f\"(ADV) Cat={len(cat_cols)} | High-card={len(high_card_cols)} | Num={len(num_cols)}\")\n",
    "\n",
    "# 2. Interactions\n",
    "inter_cols = []\n",
    "if ENABLE_INTERACTIONS and len(num_cols) >= 2:\n",
    "    base_nums = num_cols[:5]\n",
    "    pairs = list(zip(base_nums, base_nums[1:]))[:3]\n",
    "    for a,b in pairs:\n",
    "        colr = f\"{a}_div_{b}\"\n",
    "        X[colr] = X[a] / (X[b].replace(0,np.nan).fillna(X[b].median()) + 1)\n",
    "        X_test[colr] = X_test[a] / (X_test[b].replace(0,np.nan).fillna(X_test[b].median()) + 1)\n",
    "        inter_cols.append(colr)\n",
    "        cold = f\"{a}_minus_{b}\"\n",
    "        X[cold] = X[a] - X[b]; X_test[cold] = X_test[a] - X_test[b]\n",
    "        inter_cols.append(cold)\n",
    "print('Interações adicionadas:', inter_cols)\n",
    "\n",
    "# 3. Encoding\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X_enc = X.copy(); X_test_enc = X_test.copy()\n",
    "ord_cols = [c for c in cat_cols if c not in high_card_cols]\n",
    "if ord_cols:\n",
    "    X_enc[ord_cols] = encoder.fit_transform(X_enc[ord_cols])\n",
    "    X_test_enc[ord_cols] = encoder.transform(X_test_enc[ord_cols])\n",
    "\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import StratifiedKFold as SKF\n",
    "\n",
    "def target_encode_oof(series: pd.Series, y_vec: np.ndarray, n_splits=7, smoothing=12, random_state=42):\n",
    "    skf_te = SKF(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    global_mean = y_vec.mean()\n",
    "    oof_vals = pd.Series(index=series.index, dtype=float)\n",
    "    for tr_idx, val_idx in skf_te.split(series, y_vec):\n",
    "        tr_s = series.iloc[tr_idx]\n",
    "        tr_y = y_vec[tr_idx]\n",
    "        stats = pd.DataFrame({'cat': tr_s, 'y': tr_y}).groupby('cat')['y'].agg(['mean','count'])\n",
    "        counts = stats['count']; means = stats['mean']\n",
    "        smooth = (counts*means + smoothing*global_mean)/(counts+smoothing)\n",
    "        mapping = smooth.to_dict()\n",
    "        oof_vals.iloc[val_idx] = series.iloc[val_idx].map(mapping).fillna(global_mean)\n",
    "    return oof_vals.values, global_mean\n",
    "\n",
    "for c in high_card_cols:\n",
    "    te_oof, gm = target_encode_oof(X[c], y, n_splits=7, smoothing=12, random_state=RANDOM_STATE)\n",
    "    stats_full = pd.DataFrame({'cat': X[c], 'y': y}).groupby('cat')['y'].agg(['mean','count'])\n",
    "    counts_f = stats_full['count']; means_f = stats_full['mean']\n",
    "    smooth_full = (counts_f*means_f + 12*gm)/(counts_f+12)\n",
    "    mapping_f = smooth_full.to_dict()\n",
    "    X_enc[c+'_te'] = te_oof\n",
    "    X_test_enc[c+'_te'] = X_test[c].map(mapping_f).fillna(gm)\n",
    "    enc_local = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    X_enc[c] = enc_local.fit_transform(X[[c]])\n",
    "    X_test_enc[c] = enc_local.transform(X_test[[c]])\n",
    "\n",
    "# 4. Low variance removal\n",
    "low_var_cols = [c for c in X_enc.columns if X_enc[c].nunique() <= 1]\n",
    "if low_var_cols:\n",
    "    X_enc.drop(columns=low_var_cols, inplace=True)\n",
    "    X_test_enc.drop(columns=[c for c in low_var_cols if c in X_test_enc.columns], inplace=True)\n",
    "print('Low variance removidas:', low_var_cols)\n",
    "\n",
    "# 5. Feature selection multi keep_pct\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "def select_features(Xm, yv, keep_pct, rs):\n",
    "    et = ExtraTreesClassifier(n_estimators=600, random_state=rs, n_jobs=-1)\n",
    "    et.fit(Xm, yv)\n",
    "    imp = pd.Series(et.feature_importances_, index=Xm.columns).sort_values(ascending=False)\n",
    "    k = max(10, int(len(imp)*keep_pct))\n",
    "    return imp.index[:k].tolist(), imp\n",
    "\n",
    "keep_candidates = [0.85, 0.90, 0.95]\n",
    "selections = []\n",
    "skf_tmp = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "for kp in keep_candidates:\n",
    "    cols, imp = select_features(X_enc, y, kp, RANDOM_STATE)\n",
    "    rf_tmp = RandomForestClassifier(n_estimators=400, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    accs=[]\n",
    "    for tri,vai in skf_tmp.split(X_enc[cols], y):\n",
    "        rf_tmp.fit(X_enc[cols].iloc[tri], y[tri])\n",
    "        pr = rf_tmp.predict(X_enc[cols].iloc[vai])\n",
    "        accs.append(accuracy_score(y[vai], pr))\n",
    "    selections.append((kp, np.mean(accs), cols))\n",
    "selections.sort(key=lambda x: x[1], reverse=True)\n",
    "best_keep, best_acc_sel, best_cols = selections[0]\n",
    "print(f'Seleção multi keep -> {best_keep} acc={best_acc_sel:.4f}')\n",
    "X_sel = X_enc[best_cols].copy(); X_test_sel = X_test_enc[best_cols].copy()\n",
    "\n",
    "# 6. Imputação de NaNs e Infs\n",
    "X_sel.replace([np.inf,-np.inf], np.nan, inplace=True)\n",
    "X_test_sel.replace([np.inf,-np.inf], np.nan, inplace=True)\n",
    "for c in X_sel.columns:\n",
    "    if X_sel[c].isna().any():\n",
    "        X_sel[c].fillna(X_sel[c].median(), inplace=True)\n",
    "    if X_test_sel[c].isna().any():\n",
    "        X_test_sel[c].fillna(X_sel[c].median(), inplace=True)\n",
    "\n",
    "# 7. Base models\n",
    "rf_deep = RandomForestClassifier(n_estimators=1200, max_depth=None, min_samples_leaf=1, max_features='sqrt', random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_shallow = RandomForestClassifier(n_estimators=800, max_depth=10, min_samples_leaf=2, max_features=0.5, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "et = ExtraTreesClassifier(n_estimators=1300, max_depth=None, min_samples_leaf=1, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "gb = GradientBoostingClassifier(n_estimators=250, learning_rate=0.05, max_depth=3, random_state=RANDOM_STATE)\n",
    "hgb = HistGradientBoostingClassifier(learning_rate=0.06, max_leaf_nodes=31, random_state=RANDOM_STATE)\n",
    "models = {'rf_deep': rf_deep, 'rf_shallow': rf_shallow, 'et': et, 'gb': gb, 'hgb': hgb}\n",
    "\n",
    "# 8. OOF\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "probas = {n: np.zeros(len(X_sel)) for n in models}\n",
    "probas_test_folds = {n: [] for n in models}\n",
    "fold_accs=[]\n",
    "for fold,(tr_idx,val_idx) in enumerate(skf.split(X_sel,y),1):\n",
    "    X_tr, X_val = X_sel.iloc[tr_idx], X_sel.iloc[val_idx]\n",
    "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "    for n,m in models.items():\n",
    "        mm = clone(m)\n",
    "        mm.fit(X_tr, y_tr)\n",
    "        pv = mm.predict_proba(X_val)[:,1]\n",
    "        probas[n][val_idx] = pv\n",
    "        probas_test_folds[n].append(mm.predict_proba(X_test_sel)[:,1])\n",
    "    avg_val = np.mean([probas[k][val_idx] for k in models], axis=0)\n",
    "    fold_accs.append(accuracy_score(y_val, (avg_val>=0.5).astype(int)))\n",
    "print('Fold mean acc (equal weights):', round(np.mean(fold_accs),4))\n",
    "\n",
    "# 9. Pesos penalizando correlação\n",
    "M = np.vstack([probas[n] for n in models]).T\n",
    "corr_matrix = np.corrcoef(M, rowvar=False)\n",
    "lam = 0.02\n",
    "\n",
    "def score_weights(w):\n",
    "    blend = M.dot(w)\n",
    "    acc = accuracy_score(y, (blend>=0.5).astype(int))\n",
    "    corr_penalty = 0.0\n",
    "    for i in range(len(w)):\n",
    "        for j in range(i+1,len(w)):\n",
    "            corr_penalty += w[i]*w[j]*corr_matrix[i,j]\n",
    "    return acc - lam*corr_penalty\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "model_names = list(models.keys())\n",
    "best_w = np.ones(len(model_names))/len(model_names)\n",
    "best_score = score_weights(best_w)\n",
    "for _ in range(600):\n",
    "    w = rng.dirichlet([1.8]*len(model_names))\n",
    "    sc = score_weights(w)\n",
    "    if sc > best_score:\n",
    "        best_score = sc; best_w = w\n",
    "# local refine\n",
    "for i in range(len(best_w)):\n",
    "    for delta in [0.03,-0.03,0.06,-0.06]:\n",
    "        w_try = best_w.copy(); w_try[i] = max(0.0, w_try[i]+delta)\n",
    "        if w_try.sum()==0: continue\n",
    "        w_try/=w_try.sum(); sc=score_weights(w_try)\n",
    "        if sc>best_score: best_score=sc; best_w=w_try\n",
    "print('Pesos finais:', dict(zip(model_names, np.round(best_w,4))), 'score=', round(best_score,4))\n",
    "\n",
    "blend_oof = M.dot(best_w)\n",
    "acc_blend_05 = accuracy_score(y, (blend_oof>=0.5).astype(int))\n",
    "print('Blend acc thr=0.5:', round(acc_blend_05,4))\n",
    "\n",
    "# 10. Stacking\n",
    "stack_features = np.hstack([M, blend_oof.reshape(-1,1)])\n",
    "meta_lr = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
    "meta_rf = RF(n_estimators=400, max_depth=5, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "meta_lr.fit(stack_features, y)\n",
    "meta_rf.fit(stack_features, y)\n",
    "proba_lr = meta_lr.predict_proba(stack_features)[:,1]\n",
    "proba_rf = meta_rf.predict_proba(stack_features)[:,1]\n",
    "print('Stack LR thr=0.5 acc:', round(accuracy_score(y, (proba_lr>=0.5).astype(int)),4),\n",
    "      '| Stack RF thr=0.5 acc:', round(accuracy_score(y, (proba_rf>=0.5).astype(int)),4))\n",
    "\n",
    "# 11. Threshold optimization\n",
    "def optimize_threshold(proba, y_true):\n",
    "    coarse = np.linspace(0.3,0.7,81); best_t=0.5; best_a=-1\n",
    "    for t in coarse:\n",
    "        a = accuracy_score(y_true, (proba>=t).astype(int))\n",
    "        if a>best_a: best_a=a; best_t=t\n",
    "    fine = np.linspace(max(0,best_t-0.03), min(1,best_t+0.03), 121)\n",
    "    for t in fine:\n",
    "        a = accuracy_score(y_true, (proba>=t).astype(int))\n",
    "        if a>best_a: best_a=a; best_t=t\n",
    "    return best_t, best_a\n",
    "\n",
    "thr_blend, acc_blend = optimize_threshold(blend_oof, y)\n",
    "thr_lr, acc_lr = optimize_threshold(proba_lr, y)\n",
    "thr_rf, acc_rf = optimize_threshold(proba_rf, y)\n",
    "print(f'Blend opt thr={thr_blend:.4f} acc={acc_blend:.4f}')\n",
    "print(f'Stack LR opt thr={thr_lr:.4f} acc={acc_lr:.4f}')\n",
    "print(f'Stack RF opt thr={thr_rf:.4f} acc={acc_rf:.4f}')\n",
    "\n",
    "options = [('blend', acc_blend, thr_blend, blend_oof), ('stack_lr', acc_lr, thr_lr, proba_lr), ('stack_rf', acc_rf, thr_rf, proba_rf)]\n",
    "options.sort(key=lambda x: x[1], reverse=True)\n",
    "choice, choice_acc, choice_thr, choice_proba = options[0]\n",
    "print('Melhor opção:', choice, 'acc=', round(choice_acc,4), 'thr=', round(choice_thr,4))\n",
    "\n",
    "# 12. Test predictions\n",
    "test_model_probas = {n: np.mean(probas_test_folds[n], axis=0) for n in model_names}\n",
    "blend_test = np.zeros(len(X_test_sel))\n",
    "for w,name in zip(best_w, model_names):\n",
    "    blend_test += w*test_model_probas[name]\n",
    "stack_test_features = np.hstack([\n",
    "    np.vstack([test_model_probas[n] for n in model_names]).T,\n",
    "    blend_test.reshape(-1,1)\n",
    "])\n",
    "stack_lr_test = meta_lr.predict_proba(stack_test_features)[:,1]\n",
    "stack_rf_test = meta_rf.predict_proba(stack_test_features)[:,1]\n",
    "final_proba = blend_test if choice=='blend' else (stack_lr_test if choice=='stack_lr' else stack_rf_test)\n",
    "final_label = (final_proba >= choice_thr).astype(int)\n",
    "submission_adv[target_col] = final_label\n",
    "out_file = f'submission_advanced_{choice}_thr{choice_thr:.4f}.csv'\n",
    "submission_adv.to_csv(out_file, index=False)\n",
    "\n",
    "# 13. Report\n",
    "pred_choice = (choice_proba >= choice_thr).astype(int)\n",
    "print({'final_acc': choice_acc,\n",
    "       'precision': precision_score(y,pred_choice),\n",
    "       'recall': recall_score(y,pred_choice),\n",
    "       'f1': f1_score(y,pred_choice),\n",
    "       'threshold': choice_thr,\n",
    "       'mode': choice,\n",
    "       'weights': dict(zip(model_names, np.round(best_w,4))),\n",
    "       'features_used': X_sel.shape[1],\n",
    "       'submission_file': out_file})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
